\documentclass[]{article}
\usepackage[portrait, margin=5mm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{graphicx}
\pagenumbering{gobble}

\renewcommand{\.}{\hskip .75pt}

\renewcommand{\arraystretch}{1.25}

\newcommand{\fin}[1]{[\.#1\.]}

\DeclareMathOperator{\aand}{\;\wedge\;}
\DeclareMathOperator{\st}{,\;}
\DeclareMathOperator{\ex}{\,\exists}

\let\r=\rightarrow
\let\*=\cdot

\begin{document}
	
\lstset{
	basicstyle=\ttfamily\small,
	literate=
	{→}{{$\rightarrow$}}1
	{∀}{{$\forall$}}1
	{∃}{{$\exists$}}1
	{×}{{$\times$}}1
	{σ}{{$\sigma$}}1
	{τ}{{$\tau$}}1
	{α}{{$\alpha$}}1
	{γ}{{$\gamma$}}1
	{≠}{{$\neq$}}1
	{≤}{{$\leq$}}1
	{≥}{{$\geq$}}1
	{↔}{{$\leftrightarrow$}}1
	{¬}{{$\neg$}}1
	{∧}{{$\wedge$}}1
	{∨}{{$\vee$}}1
	{•}{$\bullet$}1
	{·}{$\cdot$}1
	{⬝}{$\cdot$}1
	{ℕ}{{$\mathbb{N}$}}1
	{ℤ}{{$\mathbb{Z}$}}1
	{∈}{{$\in$}}1
	{ₗ}{{$_l$}}1
	{₀}{{$_0$}}1
	{∑}{{$\;\sum$}}1
	{ᵀ}{{$^\texttt{T}$}}1
	{ᵥ}{{$_v$}}1
	{ₘ}{{$_m$}}1
	{⁻¹}{{$^{-1}$}}1
	{∞}{{$\infty$}}1
	{⊤}{{$\top$}}1
	{⊥}{{$\bot$}}1
	{⟨}{{$\langle$}}1
	{⟩}{{$\rangle$}}1
	{∘}{{$\circ$}}1
	{▸}{{$\triangleright$}}1
}

Gyula Farkas established that a system of linear inequalities has a solution if and only if we cannot obtain
a contradiction by taking a linear combination of the inequalities:
\begin{lstlisting}
theorem equalityFarkas [Fintype I] [Fintype J] [LinearOrderedField F] (A : Matrix I J F) (b : I → F) :
    (∃ x : J → F, 0 ≤ x ∧ A *ᵥ x = b) ≠ (∃ y : I → F, 0 ≤ Aᵀ *ᵥ y ∧ b ⬝ᵥ y < 0)
\end{lstlisting}

Geometric interpretation of \texttt{equalityFarkas} is as follows.
The column vectors of \texttt{A} generate a cone in the
\texttt{|I|}-dimensional Euclidean space from the origin.
The point \texttt{b} either lies inside this cone (in this case, the entries
of \texttt{x} give nonnegative coefficients which,
when applied to the column vectors of \texttt{A},
give a vector from the origin to the point \texttt{b}),
or there exists a hyperplane that contains the origin and that
strictly separates \texttt{b} from given cone
(in this case, \texttt{y} gives a normal vector of this hyperplane).

The next theorem generalizes \texttt{equalityFarkas} to structures where
multiplication does not have to be commutative;
furthermore, it supports infinitely many equations:
\begin{lstlisting}
theorem coordinateFarkasBartl {I : Type*} [Fintype J] [LinearOrderedDivisionRing R]
    (A : (I → R) →ₗ[R] J → R) (b : (I → R) →ₗ[R] R) :
    (∃ x : J → R, 0 ≤ x ∧ ∀ w : I → R, ∑ j : J, A w j • x j = b w) ≠ (∃ y : I → R, 0 ≤ A y ∧ b y < 0)
\end{lstlisting}

In the next generalization, the partially ordered module \texttt{I} $\r$ \texttt{R}
is replaced by a general \texttt{R}-module \texttt{W}:
\begin{lstlisting}
theorem almostFarkasBartl [Fintype J] [LinearOrderedDivisionRing R] [AddCommGroup W] [Module R W]
    (A : W →ₗ[R] J → R) (b : W →ₗ[R] R) :
    (∃ x : J → R, 0 ≤ x ∧ ∀ w : W, ∑ j : J, A w j • x j = b w) ≠ (∃ y : W, 0 ≤ A y ∧ b y < 0)
\end{lstlisting}

In the most general theorem, stated below, certain occurrences of \texttt{R} are replaced by
a linearly ordered \texttt{R}-module \texttt{V} whose order respects the order on \texttt{R}:
\begin{lstlisting}
theorem fintypeFarkasBartl [Fintype J] [LinearOrderedDivisionRing R]
    [LinearOrderedAddCommGroup V] [Module R V] [PosSMulMono R V] [AddCommGroup W] [Module R W]
    (A : W →ₗ[R] J → R) (b : W →ₗ[R] V) :
    (∃ x : J → V, 0 ≤ x ∧ ∀ w : W, ∑ j : J, A w j • x j = b w) ≠ (∃ y : W, 0 ≤ A y ∧ b y < 0)
\end{lstlisting}

Note that \texttt{fintypeFarkasBartl} subsumes \texttt{scalarFarkas} as well as the other versions,
since \texttt{R} can be viewed as a linearly ordered module over itself.

We have hereby stated a three-fold generalization of the original Farkas' result.
Let's prove it! Our proof, starting on the next page, is based on
a modern algebraic proof by David Bartl. We first prove a tiny-bit-less-general
version \texttt{finFarkasBartl} which uses \texttt{Fin n} (i.e., indexing by natural numbers
between \texttt{0} inclusive and \texttt{n} exclusive) instead of
an arbitrary (unordered) finite type \texttt{J}.
In the end, we obtain \texttt{fintypeFarkasBartl} from \texttt{finFarkasBartl} using
some boring mechanisms regarding equivalence between finite types.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=120mm]{AI-generated.jpg}
	\caption{AI-generated image fills the rest of the first page.}
\end{figure}

\newpage
\section*{Proving finFarkasBartl}

In this section, we prove:
\begin{lstlisting}
theorem finFarkasBartl {n : ℕ} [LinearOrderedDivisionRing R]
    [LinearOrderedAddCommGroup V] [Module R V] [PosSMulMono R V] [AddCommGroup W] [Module R W]
    (A : W →ₗ[R] Fin n → R) (b : W →ₗ[R] V) :
    (∃ x : Fin n → V, 0 ≤ x ∧ ∀ w : W, ∑ j : Fin n, A w j • x j = b w) ≠ (∃ y : W, 0 ≤ A y ∧ b y < 0)
\end{lstlisting}
We first rephrase the goal to:
\begin{lstlisting}
(∃ x : Fin n → V, 0 ≤ x ∧ ∀ w : W, ∑ j : Fin n, A w j • x j = b w) ↔ (∀ y : W, 0 ≤ A y → 0 ≤ b y)
\end{lstlisting}
Implication from left to right is immediately satisfied by the following term:
\begin{lstlisting}
fun ⟨x, hx, hb⟩ y hy => hb y ▸ Finset.sum_nonneg (fun i _ => smul_nonneg (hy i) (hx i))
\end{lstlisting}
Implication from right to left will be proved by induction on \texttt{n} with generalized \texttt{A} and \texttt{b}.
In case \texttt{n = 0} we immediately have:
\begin{lstlisting}
A_tauto (w : W) : 0 ≤ A w
\end{lstlisting}
We have an assumption:
\begin{lstlisting}
hAb : ∀ y : W, 0 ≤ A y → 0 ≤ b y
\end{lstlisting}
We set \texttt{x} to be the empty vector family. Now, for every \texttt{w :~W}, we must prove:
\begin{lstlisting}
∑ j : Fin 0, A w j • (0 : Fin 0 → V) j = b w
\end{lstlisting}
We simplify the goal to:
\begin{lstlisting}
0 = b w
\end{lstlisting}
We utilize that \texttt{V} is ordered and prove the equality as two inequalities.
Inequality \texttt{0 $\le$ b w} is directly satisfied by:
\begin{lstlisting}
hAb w (A_tauto w)
\end{lstlisting}
Inequality \texttt{b w $\le$ 0} is easily reduced to:
\begin{lstlisting}
hAb (-w) (A_tauto (-w))
\end{lstlisting}
The induction step is stated as a lemma:
\begin{lstlisting}
lemma industepFarkasBartl {m : ℕ} [LinearOrderedDivisionRing R]
    [LinearOrderedAddCommGroup V] [Module R V] [PosSMulMono R V] [AddCommGroup W] [Module R W]
    (ih : ∀ A₀ : W →ₗ[R] Fin m → R, ∀ b₀ : W →ₗ[R] V,
      (∀ y₀ : W, 0 ≤ A₀ y₀ → 0 ≤ b₀ y₀) →
        (∃ x₀ : Fin m → V, 0 ≤ x₀ ∧ ∀ w₀ : W, ∑ i₀ : Fin m, A₀ w₀ i₀ • x₀ i₀ = b₀ w₀))
    {A : W →ₗ[R] Fin m.succ → R} {b : W →ₗ[R] V} (hAb : ∀ y : W, 0 ≤ A y → 0 ≤ b y) :
    ∃ x : Fin m.succ → V, 0 ≤ x ∧ ∀ w : W, ∑ i : Fin m.succ, A w i • x i = b w
\end{lstlisting}
%First we introduce an auxiliary definition.
We define
\begin{lstlisting}
a : W →ₗ[R] Fin m → R
\end{lstlisting}
as the first \texttt{m} rows of \texttt{A} (i.e., \texttt{A} without the last row):
\begin{lstlisting}
a := (fun w : W => fun i : Fin m => A w i)
\end{lstlisting}
To prove \texttt{industepFarkasBartl} we first consider the easy case:
\begin{lstlisting}
is_easy : ∀ y : W, 0 ≤ a y → 0 ≤ b y
\end{lstlisting}
From \texttt{ih a b is\_easy} we obtain:
\begin{lstlisting}
x : Fin m → V
hx : 0 ≤ x
hxb : ∀ w₀ : W, ∑ i₀ : Fin m, a w₀ i₀ • x i₀ = b w₀
\end{lstlisting}
The lemma is satisfied by this vector family:
\begin{lstlisting}
(fun i : Fin m.succ => if hi : i < m then x i else 0)
\end{lstlisting}
Easy case analysis shows that the vector family is nonnegative.
Now we need to prove:
\begin{lstlisting}
∀ w : W, ∑ i : Fin m.succ, A w i • (fun i : Fin m.succ => if hi : i < m then x i else 0) i = b w
\end{lstlisting}
We simplify the goal to:
\begin{lstlisting}
∀ w : W, ∑ i : Fin m, A w i • x i = b w
\end{lstlisting}
This is exactly \texttt{hxb}. \newpage \noindent
Now for the hard case; negation of \texttt{is\_easy} gives us:
\begin{lstlisting}
y' : W
hay' : 0 ≤ a y'
hby' : b y' < 0
\end{lstlisting}
Let \texttt{y} be flipped and rescaled \texttt{y'} as follows:
\begin{lstlisting}
y : W := (A y' m)⁻¹ • y'
\end{lstlisting}
From \texttt{hAb} we get:
\begin{lstlisting}
hAy' : A y' m < 0
\end{lstlisting}
Therefore \texttt{hAy'.ne :~A y' m $\neq$ 0}
implies that \texttt{y} has the property that motivated the rescaling:
\begin{lstlisting}
hAy : A y m = 1
\end{lstlisting}
From \texttt{hAy} we have:
\begin{lstlisting}
hAA : ∀ w : W, A (w - (A w m • y)) m = 0
\end{lstlisting}
Using \texttt{hAA} and \texttt{hAb} we prove:
\begin{lstlisting}
hbA : ∀ w : W, 0 ≤ a (w - (A w m • y)) → 0 ≤ b (w - (A w m • y))
\end{lstlisting}
From \texttt{hbA} we have:
\begin{lstlisting}
hbAb : ∀ w : W, 0 ≤ (a - (A · m • a y)) w → 0 ≤ (b - (A · m • b y)) w
\end{lstlisting}
We observe that these two terms (appearing in \texttt{hbAb} we just proved) are linear maps:
\begin{lstlisting}
(a - (A · m • a y))
(b - (A · m • b y))
\end{lstlisting}
Therefore, we can plug them into \texttt{ih} and provide \texttt{hbAb} as the last argument.
We obtain:
\begin{lstlisting}
x' : Fin m → V
hx' : 0 ≤ x'
hxb' : ∀ w₀ : W, ∑ i₀ : Fin m, (a - (A · m • a y)) w₀ i₀ • x' i₀ = (b - (A · m • b y)) w₀
\end{lstlisting}
We claim that our lemma is satisfied by this vector family:
\begin{lstlisting}
(fun i : Fin m.succ => if hi : i < m then x' i else b y - ∑ j : Fin m, a y i • x' j)
\end{lstlisting}
Let us show the nonnegativity first.
Nonnegativity of everything except of the last vector follows from \texttt{hx'}.
From \texttt{hAy'} we have:
\begin{lstlisting}
hAy'' : (A y' m)⁻¹ ≤ 0
\end{lstlisting}
From \texttt{hAy''} with \texttt{hay'} we have:
\begin{lstlisting}
hay : a y ≤ 0
\end{lstlisting}
From \texttt{hAy''} with \texttt{hby'} converted to nonstrict inequality we have:
\begin{lstlisting}
hby : 0 ≤ b y
\end{lstlisting}
For the nonnegativity of the last vector, we need to prove:
\begin{lstlisting}
∑ j : Fin m, a y j • x' j ≤ b y
\end{lstlisting}
It follows from \texttt{hay j} with \texttt{hx' j} and \texttt{hby} using basic properties of inequalities.
The only remaining task is to show:
\begin{lstlisting}
∀ w : W, 
  ∑ i : Fin m.succ, (A w i • (if hi : i < m then x' i else b y - ∑ j : Fin m, a y j • x' j)) = b w
\end{lstlisting}
Given general \texttt{w :~W} we make a key observation (using \texttt{hxb' w}):
\begin{lstlisting}
haAa : ∑ i : Fin m, (a w i - A w m * a y i) • x' i = b w - A w m • b y
\end{lstlisting}
With the help of \texttt{haAa} we transform the goal to:
\begin{lstlisting}
∑ i : Fin m.succ, (A w i • (if hi : i < m then x' i else b y - ∑ j : Fin m, a y j • x' j)) =
∑ i : Fin m, (a w i - A w M * a y i) • x' i + A w M • b y
\end{lstlisting}
%From here, the direction should be clear; the rest of the proof is just a manipulation
%with the goal without any additional hypotheses.
We distribute $\bullet$ over \texttt{if} so that the goal becomes:
\begin{lstlisting}
∑ i : Fin m.succ, (if hi : i < m then A w i • x' i else A w i • (b y - ∑ j : Fin m, a y j • x' j)) =
∑ i : Fin m, (a w i - A w M * a y i) • x' i + A w M • b y
\end{lstlisting}
We split the left-hand side into two parts:
\begin{lstlisting}
∑ i : Fin m, (a w i • x' i) + A w M • (b y - ∑ j : Fin m, a y j • x' j) =
∑ i : Fin m, (a w i - A w M * a y i) • x' i + A w M • b y
\end{lstlisting}
The rest is a simple manipulation with sums.


\end{document}
